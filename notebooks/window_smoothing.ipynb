{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88988b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: c:\\Users\\filip\\Documents\\code\\SV-eval\n",
      "Processing directory: data\\noisy\\gaussian\\vox1_test_segments_snr_0_noisy_gaussian\n",
      "Processing with gaussian filter, window size 12ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing gaussian SNR 0 with gaussian_12ms:   7%|â–‹         | 649/9119 [00:12<02:38, 53.33it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 90\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m filter_type \u001b[38;5;129;01min\u001b[39;00m filter_types:\n\u001b[0;32m     89\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m window_size \u001b[38;5;129;01min\u001b[39;00m window_sizes:\n\u001b[1;32m---> 90\u001b[0m                 \u001b[43mprocess_dataset_with_window_filter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mnoisy_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m                    \u001b[49m\u001b[43moutput_subdir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mnoise_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msnr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfilter_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# Process background noise datasets as well\u001b[39;00m\n\u001b[0;32m    101\u001b[0m noise_types \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAirConditioner\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBabble\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeighbor\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "Cell \u001b[1;32mIn[1], line 59\u001b[0m, in \u001b[0;36mprocess_dataset_with_window_filter\u001b[1;34m(noisy_dataset, data_dir, subdir, noise_type, snr, filter_type, window_size)\u001b[0m\n\u001b[0;32m     56\u001b[0m noisy_path \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Load audio\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m audio, sample_rate \u001b[38;5;241m=\u001b[39m \u001b[43mtorchaudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Apply window filter\u001b[39;00m\n\u001b[0;32m     62\u001b[0m filtered_audio \u001b[38;5;241m=\u001b[39m apply_window_filter(\n\u001b[0;32m     63\u001b[0m     audio, filter_type, window_size, sample_rate\n\u001b[0;32m     64\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\filip\\Documents\\code\\SV-eval\\.venv\\Lib\\site-packages\\torchaudio\\_backend\\utils.py:205\u001b[0m, in \u001b[0;36mget_load_func.<locals>.load\u001b[1;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size, backend)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load audio data from source.\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03mBy default (``normalize=True``, ``channels_first=True``), this function returns Tensor with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03m        `[channel, time]` else `[time, channel]`.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    204\u001b[0m backend \u001b[38;5;241m=\u001b[39m dispatcher(uri, \u001b[38;5;28mformat\u001b[39m, backend)\n\u001b[1;32m--> 205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\filip\\Documents\\code\\SV-eval\\.venv\\Lib\\site-packages\\torchaudio\\_backend\\soundfile.py:27\u001b[0m, in \u001b[0;36mSoundfileBackend.load\u001b[1;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m     19\u001b[0m     uri: Union[BinaryIO, \u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m     buffer_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4096\u001b[39m,\n\u001b[0;32m     26\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msoundfile_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\filip\\Documents\\code\\SV-eval\\.venv\\Lib\\site-packages\\torchaudio\\_backend\\soundfile_backend.py:221\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filepath, frame_offset, num_frames, normalize, channels_first, format)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;129m@_requires_soundfile\u001b[39m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m    141\u001b[0m     filepath: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28mformat\u001b[39m: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    147\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;28mint\u001b[39m]:\n\u001b[0;32m    148\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load audio data from file.\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \n\u001b[0;32m    150\u001b[0m \u001b[38;5;124;03m    Note:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;124;03m            `[channel, time]` else `[time, channel]`.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 221\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43msoundfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file_:\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m file_\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWAV\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m normalize:\n\u001b[0;32m    223\u001b[0m             dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\filip\\Documents\\code\\SV-eval\\.venv\\Lib\\site-packages\\soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    655\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    657\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[1;32m--> 658\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n\u001b[0;32m    661\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\filip\\Documents\\code\\SV-eval\\.venv\\Lib\\site-packages\\soundfile.py:1205\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1203\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1204\u001b[0m             file \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mencode(_sys\u001b[38;5;241m.\u001b[39mgetfilesystemencoding())\n\u001b[1;32m-> 1205\u001b[0m     file_ptr \u001b[38;5;241m=\u001b[39m \u001b[43mopenfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1206\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(file, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m   1207\u001b[0m     file_ptr \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_open_fd(file, mode_int, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info, closefd)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Change to root directory\n",
    "os.chdir(\"..\")\n",
    "from src.utils import *\n",
    "\n",
    "print(\"Current Working Directory:\", os.getcwd())\n",
    "\n",
    "# Define filter types and window sizes to use\n",
    "filter_types = [\"gaussian\", \"median\"]\n",
    "window_sizes = [12, 25, 50]  # in milliseconds\n",
    "\n",
    "# Setup data paths\n",
    "data_dir = \"data\"\n",
    "data_type = \"noisy\"\n",
    "noise_types = [\"gaussian\", \"poisson\", \"rayleigh\"]\n",
    "snrs = [0, 5, 10, 15, 20]\n",
    "output_subdir = \"window_smoothing\"\n",
    "\n",
    "\n",
    "# Create a function to process and filter the dataset\n",
    "def process_dataset_with_window_filter(\n",
    "    noisy_dataset, data_dir, subdir, noise_type, snr, filter_type, window_size\n",
    "):\n",
    "    \"\"\"\n",
    "    Process a dataset applying a window filter and save the results\n",
    "\n",
    "    Args:\n",
    "        noisy_dataset: DataFrame containing paths to noisy audio files\n",
    "        data_dir: Root data directory\n",
    "        subdir: Output subdirectory\n",
    "        noise_type: Type of noise in the dataset\n",
    "        filter_type: Type of filter to apply ('gaussian' or 'median')\n",
    "        window_size: Size of the filter window in milliseconds\n",
    "    \"\"\"\n",
    "    dataset_name = f\"vox1_test_wav_snr_{snr}_{noise_type}\"\n",
    "    output_dir = os.path.join(\n",
    "        data_dir, subdir, f\"filter_{filter_type}_{window_size}ms\", noise_type, dataset_name\n",
    "    )\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"Processing with {filter_type} filter, window size {window_size}ms\")\n",
    "\n",
    "    for index, row in tqdm(\n",
    "        noisy_dataset.iterrows(),\n",
    "        total=noisy_dataset.shape[0],\n",
    "        desc=f\"Processing {noise_type} SNR {snr} with {filter_type}_{window_size}ms\",\n",
    "    ):\n",
    "        noisy_path = row[\"path\"]\n",
    "\n",
    "        # Load audio\n",
    "        audio, sample_rate = torchaudio.load(noisy_path)\n",
    "\n",
    "        # Apply window filter\n",
    "        filtered_audio = apply_window_filter(\n",
    "            audio, filter_type, window_size, sample_rate\n",
    "        )\n",
    "\n",
    "        # Create output directory structure\n",
    "        person_subdir = os.path.join(output_dir, row[\"person_id\"])\n",
    "        os.makedirs(person_subdir, exist_ok=True)\n",
    "\n",
    "        # Save filtered audio\n",
    "        filtered_audio_path = os.path.join(person_subdir, os.path.basename(noisy_path))\n",
    "        torchaudio.save(filtered_audio_path, filtered_audio, sample_rate)\n",
    "\n",
    "\n",
    "# Process all datasets with all filter combinations\n",
    "for noise_type in noise_types:\n",
    "    for snr in snrs:\n",
    "        dataset_name = f\"vox1_test_segments_snr_{snr}_noisy_{noise_type}\"\n",
    "\n",
    "        noisy_dt_path = os.path.join(data_dir, data_type, noise_type, dataset_name)\n",
    "        if not os.path.exists(noisy_dt_path):\n",
    "            print(f\"Directory {noisy_dt_path} does not exist\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing directory: {noisy_dt_path}\")\n",
    "        noisy_dataset = scan_directory_voxceleb2(noisy_dt_path)\n",
    "\n",
    "        for filter_type in filter_types:\n",
    "            for window_size in window_sizes:\n",
    "                process_dataset_with_window_filter(\n",
    "                    noisy_dataset,\n",
    "                    data_dir,\n",
    "                    output_subdir,\n",
    "                    noise_type,\n",
    "                    snr,    \n",
    "                    filter_type,\n",
    "                    window_size,\n",
    "                )\n",
    "\n",
    "# Process background noise datasets as well\n",
    "noise_types = [\"AirConditioner\", \"Babble\", \"Neighbor\"]\n",
    "data_type = \"noisy_bg\\\\vox1_test_wav_bq_noise\"\n",
    "\n",
    "for noise_type in noise_types:\n",
    "    for snr in snrs:\n",
    "        dataset_name = f\"vox1_test_wav_snr_{snr}_{noise_type}\"\n",
    "\n",
    "        noisy_dt_path = os.path.join(data_dir, data_type, noise_type, dataset_name)\n",
    "        if not os.path.exists(noisy_dt_path):\n",
    "            print(f\"Directory {noisy_dt_path} does not exist\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing directory: {noisy_dt_path}\")\n",
    "        noisy_dataset = scan_directory_voxceleb2(noisy_dt_path)\n",
    "\n",
    "        for filter_type in filter_types:\n",
    "            for window_size in window_sizes:\n",
    "                process_dataset_with_window_filter(\n",
    "                    noisy_dataset,\n",
    "                    data_dir,\n",
    "                    output_subdir,\n",
    "                    noise_type,\n",
    "                    snr,\n",
    "                    filter_type,\n",
    "                    window_size,\n",
    "                )\n",
    "\n",
    "\n",
    "print(\"Processing complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
